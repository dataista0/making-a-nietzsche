# Making a Nietzsche

## Welcome to my transfer learning for nlp research journal

Long story short, trying to get acquainted with the most recent nlp pre-trained models (ULMFit, BERT, GPT, GPT-2 and XLNet) I'm trying to create a language model able to generate Nietzsche-like prose of a reasonable quality. I just started and my results are not even close to good... but I think the process of trying to create one using these technologies is interesting by itself, so I'm writing a research journal and not a result-oriented post.

## Current notebooks:

* [Making a Nietzsche - 1. Research Journal & ULMFit](nbs/Making%20a%20Nietzsche%20-%201.%20Research%20Journal%20%26%20ULMFit.ipynb)
* [GPT-2 - Large (774M params) with Pytorch: Not that impressive](nbs/GPT2-Large%20-774M-%20with%20Pytorch%20-%20Not%20that%20impressive.ipynb)
* [GPT2-Large - Day 2 - More friendly experiments - maybe impressive](/nbs/GPT2-Large%20-%20Day%202%20-%20More%20friendly%20experiments%20-%20maybe%20impressive.ipynb)
